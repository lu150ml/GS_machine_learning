# GS Machine Learning

<p align="center">
  <img src="https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white" alt="Python" />
  <img src="https://img.shields.io/badge/Pandas-150458?logo=pandas&logoColor=white" alt="Pandas" />
  <img src="https://img.shields.io/badge/scikit--learn-F7931E?logo=scikit-learn&logoColor=white" alt="scikit-learn" />
  <img src="https://img.shields.io/badge/XGBoost-EC4D37?logo=xgboost&logoColor=white" alt="XGBoost" />
  <img src="https://img.shields.io/badge/LightGBM-013243?logoColor=white" alt="LightGBM" />
  <img src="https://img.shields.io/badge/Seaborn-4E79A7?logoColor=white" alt="Seaborn" />
  <img src="https://img.shields.io/badge/Matplotlib-11557C?logoColor=white" alt="Matplotlib" />
  <img src="https://img.shields.io/badge/SHAP-FF6F61?logoColor=white" alt="SHAP" />
  <img src="https://img.shields.io/badge/Google%20Colab-F9AB00?logo=googlecolab&logoColor=white" alt="Google Colab" />
</p>

Projeto acad√™mico focado em treinar modelos de classifica√ß√£o para prever se startups ser√£o **adquiridas ou fechar√£o**. Todo o fluxo ‚Äî da an√°lise explorat√≥ria ao p√≥s-modelagem ‚Äî est√° dispon√≠vel no notebook [`gs_machine_learning.ipynb`](gs_machine_learning.ipynb), que pode ser executado tanto localmente quanto no Google Colab.

## üìä Vis√£o geral
- **Fonte dos dados**: arquivo `startup data (1).csv`, contendo informa√ß√µes hist√≥ricas e financeiras de startups (financiamentos, marcos, localiza√ß√£o, etc.).
- **Objetivo**: estimar a probabilidade de aquisi√ß√£o a partir de atributos num√©ricos e categ√≥ricos.
- **Output principal**: modelos treinados e interpretados, com destaque para um **XGBoost otimizado** e um **ensemble soft voting** que combinam XGBoost, SVM e MLP.

## ‚ú® Principais etapas do notebook
1. **Importa√ß√£o e checagens iniciais** ‚Äì leitura do CSV, inspe√ß√£o de forma, amostras e colunas.
2. **An√°lise explorat√≥ria** ‚Äì contagens normalizadas de `status`, distribui√ß√µes por estado/categoria e auditoria de valores ausentes.
3. **Limpeza e pr√©-processamento** ‚Äì remo√ß√£o de colunas redundantes, imputa√ß√£o de campos temporais e normaliza√ß√£o pontual.
4. **Feature engineering avan√ßada** ‚Äì cria√ß√£o de m√©tricas como `funding_per_round`, `funding_span`, `num_rounds_active`, `rel_invest_ratio` e `vc_investment_strength`.
5. **Treinamento de modelos** ‚Äì Decision Tree como baseline e modelos avan√ßados (XGBoost, SVM, MLP e ensemble) com busca de hiperpar√¢metros via `GridSearchCV`.
6. **Avalia√ß√£o** ‚Äì m√©tricas de acur√°cia, classification report e matriz de confus√£o, al√©m de comparativos visuais.
7. **Interpretabilidade** ‚Äì import√¢ncia de features com XGBoost e explica√ß√µes globais com SHAP, incluindo estudos de caso (√≠ndices 331‚Äì552).

## üìÅ Estrutura
```
‚îú‚îÄ‚îÄ README.md                     # Este guia
‚îî‚îÄ‚îÄ gs_machine_learning.ipynb     # Notebook principal com todo o pipeline
```

## üß± Pr√©-requisitos
- Python 3.10+
- Pip ou outro gerenciador de pacotes compat√≠vel

Depend√™ncias principais (instaladas no notebook ou manualmente):
```
pandas numpy scikit-learn xgboost lightgbm seaborn matplotlib shap scipy
```

## üöÄ Passo a passo para executar localmente
1. **Clone o reposit√≥rio**
   ```bash
   git clone https://github.com/lu150ml/GS_machine_learning.git
   cd GS_machine_learning
   ```
2. **Crie um ambiente virtual (opcional, mas recomendado)**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # Linux/macOS
   .venv\Scripts\activate    # Windows
   ```
3. **Instale as depend√™ncias**
   ```bash
   pip install -r requirements.txt  # se voc√™ criar um arquivo
   # ou instale diretamente:
   pip install pandas numpy scikit-learn xgboost lightgbm seaborn matplotlib shap scipy
   ```
4. **Disponibilize o dataset**
   - Baixe `startup data (1).csv` e coloque-o no diret√≥rio raiz ou ajuste o caminho na constante `PATH` logo no in√≠cio do notebook.
5. **Execute o notebook**
   ```bash
   jupyter notebook gs_machine_learning.ipynb
   ```
   Em seguida, rode as c√©lulas na ordem para reproduzir todo o fluxo.

## ‚òÅÔ∏è Executando no Google Colab
1. Clique no badge "Open in Colab" presente na primeira c√©lula do notebook (ou [acesse diretamente](https://colab.research.google.com/github/lu150ml/GS_machine_learning/blob/main/gs_machine_learning.ipynb)).
2. Fa√ßa upload do arquivo `startup data (1).csv` para o ambiente Colab (ou monte seu Google Drive e ajuste o `PATH`).
3. Execute as c√©lulas sequencialmente:
   - Instala√ß√£o de depend√™ncias extras (caso solicitado).
   - Importa√ß√£o de bibliotecas e leitura dos dados.
   - EDA, engenharia de atributos e treinamento dos modelos.
4. Utilize os gr√°ficos gerados (matriz de confus√£o, compara√ß√£o de acur√°cia, plots SHAP) para interpretar os resultados.

## üìà Resultados e insights
- **Modelos avan√ßados**: o XGBoost otimizado apresentou o melhor equil√≠brio entre precis√£o e interpretabilidade, sendo usado como base para explica√ß√µes SHAP.
- **Ensemble soft voting**: ao ponderar XGBoost (peso 3) com SVM e MLP (peso 1 cada), obteve-se uma melhora marginal na acur√°cia e maior robustez.
- **Principais drivers**: vari√°veis temporais (`age_last_milestone_year`, `age_first_funding_year`), intensidade de investimento (`funding_total_usd`, `funding_rounds`) e relacionamentos (`relationships`, `avg_participants`) foram determinantes para classificar casos reais do dataset.

## üõ†Ô∏è Pr√≥ximos passos sugeridos
- Criar um arquivo `requirements.txt` formal para simplificar a instala√ß√£o.
- Salvar modelos treinados (pickle) e expor uma API leve para scoring.
- Integrar novas fontes de dados (ex.: m√©tricas de tra√ß√£o atualizadas) e testar t√©cnicas de balanceamento como SMOTE.

Sinta-se √† vontade para abrir *issues* ou enviar *pull requests* com melhorias! üí°
